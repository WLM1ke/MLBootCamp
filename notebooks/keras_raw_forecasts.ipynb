{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from sklearn import model_selection\n",
    "import pathlib\n",
    "\n",
    "COORDINATES = [\"Xmin\", \"Ymin\", \"Xmax\", \"Ymax\"]\n",
    "MAX_TRAIN_FORECASTS = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = pd.read_csv(\"../raw/train_data.csv\").set_index(\"itemId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = pd.read_csv(\"../raw/train_answers.csv\").set_index(\"itemId\")\n",
    "answers.columns = COORDINATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_test = pd.read_csv(\"../raw/test_data.csv\").set_index(\"itemId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_batch(batch_size):\n",
    "    while True:\n",
    "        item_id = np.random.choice(votes.index, 1)\n",
    "        forecasts = votes.loc[item_id].set_index(\"userId\")\n",
    "        x = np.zeros((1, len(forecasts), 4),)\n",
    "        y = np.zeros((1, 4))\n",
    "        \n",
    "        x[0] = forecasts.sample(len(forecasts))\n",
    "        y[0] = answers.loc[item_id]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(boxes_pred, boxes_true):\n",
    "\n",
    "    x_min = K.stack([boxes_pred[:, 0], boxes_true[:, 0]], axis=-1)\n",
    "    y_min = K.stack([boxes_pred[:, 1], boxes_true[:, 1]], axis=-1)\n",
    "    x_max = K.stack([boxes_pred[:, 2], boxes_true[:, 2]], axis=-1)\n",
    "    y_max = K.stack([boxes_pred[:, 3], boxes_true[:, 3]], axis=-1)\n",
    "\n",
    "    x_min = K.max(x_min, axis=-1)\n",
    "    y_min = K.max(y_min, axis=-1)\n",
    "    x_max = K.min(x_max, axis=-1)\n",
    "    y_max = K.min(y_max, axis=-1)\n",
    "\n",
    "    zeros = K.zeros_like(x_max)\n",
    "\n",
    "    x_inter = K.stack([zeros, x_max - x_min], axis=-1)\n",
    "    y_inter = K.stack([zeros, y_max - y_min], axis=-1)\n",
    "\n",
    "    x_inter = K.max(x_inter, axis=-1)\n",
    "    y_inter = K.max(y_inter, axis=-1)\n",
    "    inter_area = x_inter * y_inter\n",
    "    \n",
    "    area_pred = (K.max(K.stack([zeros, boxes_pred[:, 2] - boxes_pred[:, 0]], axis=-1), axis=-1) * \n",
    "                 K.max(K.stack([zeros, boxes_pred[:, 3] - boxes_pred[:, 1]], axis=-1), axis=-1))\n",
    "    area_true = (K.max(K.stack([zeros, boxes_true[:, 2] - boxes_true[:, 0]], axis=-1), axis=-1) * \n",
    "                 K.max(K.stack([zeros, boxes_true[:, 3] - boxes_true[:, 1]], axis=-1), axis=-1))\n",
    "\n",
    "    iou = inter_area / (area_pred + area_true - inter_area + K.epsilon())\n",
    "    \n",
    "    return -K.mean(iou, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(filters):\n",
    "    K.clear_session()\n",
    "    \n",
    "    y = x = layers.Input(shape=(None, 4))\n",
    "    \n",
    "    y = layers.Bidirectional(layers.LSTM(\n",
    "        units=filters,\n",
    "        return_sequences=True\n",
    "    ))(y)\n",
    "    y = layers.GlobalAveragePooling1D()(y)\n",
    "        \n",
    "    y = layers.Dense(\n",
    "        units=filters,\n",
    "        activation=\"relu\"\n",
    "    )(y)\n",
    "    y = layers.Dense(\n",
    "        units=filters // 2,\n",
    "        activation=\"relu\"\n",
    "    )(y)\n",
    "    y = layers.Dense(\n",
    "        units=filters // 4,\n",
    "        activation=\"relu\"\n",
    "    )(y)\n",
    "    y = layers.Dense(\n",
    "        units=4,\n",
    "        activation=\"relu\"\n",
    "    )(y)\n",
    "    \n",
    "    model = models.Model(inputs=x, outputs=y)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(batch_size, units, epochs=20):\n",
    "    model = make_model(units)\n",
    "    \n",
    "    lr=0.002\n",
    "    \n",
    "    # Предварительное обучение на MAE\n",
    "    model.compile(optimizer=optimizers.Nadam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004),\n",
    "                  loss=\"mean_absolute_error\",\n",
    "                  metrics=[intersection_over_union]\n",
    "    )\n",
    "    model.fit_generator(\n",
    "        yield_batch(batch_size),\n",
    "        steps_per_epoch=1000,\n",
    "        epochs=epochs,\n",
    "        callbacks=[\n",
    "            # callbacks.EarlyStopping(monitor='loss', patience=epochs // 10, verbose=10)\n",
    "            callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=1, verbose=1)\n",
    "        ],\n",
    "        # validation_data=None,\n",
    "    )\n",
    "    \n",
    "    # ФИнальное обучение\n",
    "    model.compile(optimizer=optimizers.Nadam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004),\n",
    "                  loss=intersection_over_union,\n",
    "                  metrics=None\n",
    "    )\n",
    "    cb = [\n",
    "        # callbacks.ModelCheckpoint(\"../processed/model.h5\", monitor=\"val_loss\", verbose=1, save_best_only=True),\n",
    "        callbacks.EarlyStopping(monitor='loss', patience=epochs // 10, verbose=10),\n",
    "        callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=1, verbose=1)\n",
    "    ]\n",
    "    model.fit_generator(\n",
    "        yield_batch(batch_size),\n",
    "        steps_per_epoch=1000 // batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=cb,\n",
    "        # validation_data=[make_feat(votes), answers],\n",
    "    )\n",
    "    model.compile(optimizer=optimizers.Nadam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004),\n",
    "                  loss=intersection_over_union,\n",
    "                  metrics=None\n",
    "    )\n",
    "    cb = [\n",
    "        # callbacks.ModelCheckpoint(\"../processed/model.h5\", monitor=\"val_loss\", verbose=1, save_best_only=True),\n",
    "        callbacks.EarlyStopping(monitor='loss', patience=epochs // 10, verbose=10),\n",
    "        callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=1, verbose=1)\n",
    "    ]\n",
    "    rez = model.fit_generator(\n",
    "        yield_batch(batch_size),\n",
    "        steps_per_epoch=1000 // batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=cb,\n",
    "        # validation_data=[make_feat(votes), answers],\n",
    "    )\n",
    "    return rez, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 4)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 256)         136192    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 179,556\n",
      "Trainable params: 179,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 415.4932 - intersection_over_union: 0.0000e+00\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 405.8378 - intersection_over_union: 0.0000e+00\n",
      "Epoch 3/20\n",
      " 422/1000 [===========>..................] - ETA: 4s - loss: 399.0098 - intersection_over_union: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "rez, model = train_model(1, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rez.history)[[\"loss\", \"val_loss\"]].plot(figsize=(16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_forecast(model):\n",
    "    subdir = time.strftime('%Y-%m-%d_%H-%M')\n",
    "    path = pathlib.Path(f\"../processed/{subdir}\")\n",
    "    path.mkdir(exist_ok=True)\n",
    "    feat = make_feat(votes_test)\n",
    "    df = model.predict(feat)\n",
    "    df = pd.DataFrame(df, index=feat.index)\n",
    "    df.to_csv(path / \"_sub_full.csv\", header=False)\n",
    "    # path.rename(path.parent / f\"{subdir}-{score:0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_forecast(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
