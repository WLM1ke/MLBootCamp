{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COORDINATES = [\"Xmin\", \"Ymin\", \"Xmax\", \"Ymax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WLMike/Documents/PycharmProjects/ML_venv/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/WLMike/Documents/PycharmProjects/ML_venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "answers = pd.read_csv(\"../raw/train_answers.csv\").set_index(\"itemId\")\n",
    "answers.columns = COORDINATES\n",
    "scaler = preprocessing.StandardScaler().fit(np.vstack([answers.values, answers.values[:, [2, 3, 0, 1]]]))\n",
    "answers[COORDINATES] = scaler.transform(answers[COORDINATES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WLMike/Documents/PycharmProjects/ML_venv/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "votes = pd.read_csv(\"../raw/train_data.csv\").set_index(\"itemId\")\n",
    "votes[COORDINATES] = scaler.transform(votes[COORDINATES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/WLMike/Documents/PycharmProjects/ML_venv/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "votes_test = pd.read_csv(\"../raw/test_data.csv\").set_index(\"itemId\")\n",
    "votes_test[COORDINATES] = scaler.transform(votes_test[COORDINATES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_center(y):\n",
    "    center_x = (y[0, 2] + y[0, 0]) / 2\n",
    "    center_y = (y[0, 3] + y[0, 1]) / 2 \n",
    "    return np.array([center_x, center_y, center_x, center_y])\n",
    "\n",
    "\n",
    "def scale(x, y, err=0.1):\n",
    "    center = find_center(y)\n",
    "    x, y = x - np.reshape(center, (1, 1, 4)), y - np.reshape(center, (1, 4))\n",
    "    \n",
    "    err_x, err_y = np.random.random(2)  \n",
    "    \n",
    "    err_x = 1 + (2 * err_x - 1) * err\n",
    "    err_y = 1 + (2 * err_y - 1) * err\n",
    "    \n",
    "    err = np.array([err_x, err_y, err_x, err_y])\n",
    "    \n",
    "    return (x * np.reshape(err, (1, 1, 4)) + np.reshape(center, (1, 1, 4)), \n",
    "            y * np.reshape(err, (1, 4)) + np.reshape(center, (1, 4)))\n",
    "    \n",
    "\n",
    "def move(x, y, err=0.1):\n",
    "    center = find_center(y)\n",
    "    x, y = x - np.reshape(center, (1, 1, 4)), y - np.reshape(center, (1, 4))\n",
    "    \n",
    "    size_x = (y[0, 2] - y[0, 0]) / 2\n",
    "    size_y = (y[0, 3] - y[0, 1]) / 2\n",
    "    \n",
    "    err_cx, err_cy = np.random.random(2)  \n",
    "    \n",
    "    err_cx = (2 * size_x * err_cx - size_x) * err\n",
    "    err_cy = (2 * size_y * err_cy - size_y) * err\n",
    "    \n",
    "    err = np.array([err_cx, err_cy, err_cx, err_cy])\n",
    "    \n",
    "    return x + np.reshape(err + center, (1, 1, 4)), y + np.reshape(err + center, (1, 4))\n",
    "    \n",
    "def aug_batch(x, y, err=0.1):\n",
    "    x, y = scale(x, y, err)\n",
    "    x, y = move(x, y, err)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_batch(data):\n",
    "    votes, answers = data\n",
    "    while True:\n",
    "        item_id = np.random.choice(votes.index, 1)\n",
    "        forecasts = votes.loc[item_id].set_index(\"userId\")\n",
    "        x = np.zeros((1, len(forecasts), 4),)\n",
    "        y = np.zeros((1, 4))\n",
    "        \n",
    "        x[0] = forecasts.sample(len(forecasts))\n",
    "        y[0] = answers.loc[item_id]\n",
    "        yield aug_batch(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_batch_val(data):\n",
    "    votes, answers = data\n",
    "    item_ids = set(votes.index)\n",
    "    while True:\n",
    "        for item_id in item_ids:\n",
    "            forecasts = votes.loc[item_id].set_index(\"userId\")\n",
    "            x = np.zeros((1, len(forecasts), 4),)\n",
    "            y = np.zeros((1, 4))\n",
    "\n",
    "            x[0] = forecasts\n",
    "            y[0] = answers.loc[item_id]\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_batch_test(data):\n",
    "    item_ids = data.index.unique()\n",
    "    for item_id in item_ids:\n",
    "        forecasts = data.loc[item_id].set_index(\"userId\")\n",
    "        x = np.zeros((1, len(forecasts), 4),)\n",
    "        y = np.zeros((1, 4))\n",
    "        x[0] = forecasts\n",
    "        yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(boxes_pred, boxes_true):\n",
    "\n",
    "    x_min = K.stack([boxes_pred[:, 0], boxes_true[:, 0]], axis=-1)\n",
    "    y_min = K.stack([boxes_pred[:, 1], boxes_true[:, 1]], axis=-1)\n",
    "    x_max = K.stack([boxes_pred[:, 2], boxes_true[:, 2]], axis=-1)\n",
    "    y_max = K.stack([boxes_pred[:, 3], boxes_true[:, 3]], axis=-1)\n",
    "\n",
    "    x_min = K.max(x_min, axis=-1)\n",
    "    y_min = K.max(y_min, axis=-1)\n",
    "    x_max = K.min(x_max, axis=-1)\n",
    "    y_max = K.min(y_max, axis=-1)\n",
    "\n",
    "    zeros = K.zeros_like(x_max)\n",
    "\n",
    "    x_inter = K.stack([zeros, x_max - x_min], axis=-1)\n",
    "    y_inter = K.stack([zeros, y_max - y_min], axis=-1)\n",
    "\n",
    "    x_inter = K.max(x_inter, axis=-1)\n",
    "    y_inter = K.max(y_inter, axis=-1)\n",
    "    inter_area = x_inter * y_inter\n",
    "    \n",
    "    area_pred = (K.max(K.stack([zeros, boxes_pred[:, 2] - boxes_pred[:, 0]], axis=-1), axis=-1) * \n",
    "                 K.max(K.stack([zeros, boxes_pred[:, 3] - boxes_pred[:, 1]], axis=-1), axis=-1))\n",
    "    area_true = (K.max(K.stack([zeros, boxes_true[:, 2] - boxes_true[:, 0]], axis=-1), axis=-1) * \n",
    "                 K.max(K.stack([zeros, boxes_true[:, 3] - boxes_true[:, 1]], axis=-1), axis=-1))\n",
    "\n",
    "    iou = inter_area / (area_pred + area_true - inter_area + K.epsilon())\n",
    "    \n",
    "    return -K.mean(iou, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(filters):\n",
    "    K.clear_session()\n",
    "    \n",
    "    y = x = layers.Input(shape=(None, 4))\n",
    "    \n",
    "    mul = 4\n",
    "    y = layers.Bidirectional(layers.LSTM(\n",
    "        units=filters * mul,\n",
    "        return_sequences=True\n",
    "    ))(y)\n",
    "    y = layers.Bidirectional(layers.LSTM(\n",
    "        units=filters * mul,\n",
    "        return_sequences=False\n",
    "    ))(y)\n",
    "    \n",
    "    y = layers.Dense(\n",
    "        units=filters * 4,\n",
    "        activation=\"relu\"\n",
    "    )(y)\n",
    "    y = layers.Dense(\n",
    "        units=filters * 2,\n",
    "        activation=\"relu\"\n",
    "    )(y)\n",
    "    y = layers.Dense(\n",
    "        units=filters,\n",
    "        activation=\"relu\"\n",
    "    )(y)\n",
    "    y = layers.Dense(\n",
    "        units=4,\n",
    "        activation=None\n",
    "    )(y)\n",
    "    \n",
    "    model = models.Model(inputs=x, outputs=y)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(callbacks.Callback):\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.1, steps=1000, gamma=0.01, tail=0.1, test=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = steps * (1 - tail) / 2\n",
    "        self.gamma = gamma\n",
    "        self.tail = 2 * tail / (1 - tail) \n",
    "        self.test = test\n",
    "        \n",
    "        if test:\n",
    "            self.step_size = 10000\n",
    "        \n",
    "        self.iterations = 0\n",
    "        self.history = {}\n",
    "        \n",
    "    def clr(self):\n",
    "        if self.test:\n",
    "            return self.base_lr * (self.max_lr / self.base_lr) ** (self.iterations / self.step_size) \n",
    "        \n",
    "        cycle = self.iterations / self.step_size\n",
    "        \n",
    "        if cycle < 1:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr) * cycle\n",
    "        \n",
    "        if cycle < 2:\n",
    "            return self.max_lr - (self.max_lr-self.base_lr) * (cycle - 1)\n",
    "\n",
    "        return self.base_lr * self.gamma ** ((cycle - 2) / self.tail)\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.iterations = 0\n",
    "        self.history = {}\n",
    "        K.set_value(self.model.optimizer.lr, self.base_lr)     \n",
    "            \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if self.test and self.iterations > self.step_size:\n",
    "            return\n",
    "        \n",
    "        self.history.setdefault(\"iterations\", []).append(self.iterations)\n",
    "        self.history.setdefault(\"lr\", []).append(K.get_value(self.model.optimizer.lr))\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "            \n",
    "        self.iterations += 1\n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nLearning rate: {K.get_value(self.model.optimizer.lr):.1e}\")\n",
    "        \n",
    "    def plot(self, smooth=None):\n",
    "        smooth = int(smooth or self.step_size // 100)\n",
    "        if self.test:\n",
    "            df = pd.DataFrame(self.history).set_index(\"lr\").loss.rolling(smooth).mean()\n",
    "            print(f\"Максимальная скорость обучения - {df.idxmin():.1e}\")\n",
    "            df.plot(logx=True, figsize=(16, 8))\n",
    "        else:\n",
    "            df = pd.DataFrame(self.history).set_index(\"iterations\")[[\"loss\", \"lr\"]].rolling(smooth).mean()\n",
    "            df.plot(figsize=(16, 8), secondary_y=\"lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_train, data_val, units):\n",
    "    \n",
    "    base_lr = 1e-05\n",
    "    max_lr = 3e-04\n",
    "    \n",
    "    steps = 100000\n",
    "    steps_per_epoch = 1000\n",
    "    epochs = steps // steps_per_epoch\n",
    "    \n",
    "    model = make_model(units)  \n",
    "    \n",
    "    model.compile(optimizer=optimizers.Nadam(lr=base_lr, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004),\n",
    "                      loss=\"mae\",\n",
    "                      metrics=[intersection_over_union]\n",
    "        )\n",
    "    rez = model.fit_generator(\n",
    "            yield_batch(data_train),\n",
    "            steps_per_epoch=1000,\n",
    "            epochs=1,\n",
    "            callbacks=None,\n",
    "            validation_data=yield_batch_val(data_val),\n",
    "            validation_steps=len(data_val[1].index)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=optimizers.Nadam(lr=base_lr, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004),\n",
    "                  loss=intersection_over_union,\n",
    "                  metrics=None\n",
    "    )\n",
    "    cycle = CyclicLR(base_lr=base_lr, max_lr=max_lr, steps=steps)\n",
    "    cb = [\n",
    "        callbacks.ModelCheckpoint(\"../processed/model.h5\", monitor=\"val_loss\", verbose=1, save_best_only=True),\n",
    "        cycle\n",
    "    ]\n",
    "    rez = model.fit_generator(\n",
    "        yield_batch(data_train),\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        callbacks=cb,\n",
    "        validation_data=yield_batch_val(data_val),\n",
    "        validation_steps=len(data_val[1].index)\n",
    "        )\n",
    "    \n",
    "    model = models.load_model(\"../processed/model.h5\", custom_objects={\"intersection_over_union\": intersection_over_union})\n",
    "    \n",
    "    return rez, cycle, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5\n",
    "\n",
    "def train_oof(train_set, test_set, units=16):\n",
    "    x_train, y_train = train_set\n",
    "    x_test = test_set\n",
    "\n",
    "    y_oof = pd.DataFrame(0, index=y_train.index, columns=COORDINATES)\n",
    "    y_pred = pd.DataFrame(0, index=x_test.index.unique(), columns=COORDINATES)\n",
    "    scores = []\n",
    "    folds = model_selection.KFold(n_splits=FOLDS, shuffle=True)\n",
    "    \n",
    "    for n, (index_train, index_valid) in enumerate(folds.split(y_train), 1):\n",
    "        print(f\"\\nFold - {n} / {FOLDS}\")\n",
    "        \n",
    "        ids_train = y_train.index[index_train]\n",
    "        ids_valid = y_train.index[index_valid]\n",
    "        \n",
    "        data_train = (x_train.loc[ids_train], y_train.loc[ids_train])\n",
    "        data_val = (x_train.loc[ids_valid], y_train.loc[ids_valid])\n",
    "        \n",
    "        rez, cycle, model = train_model(data_train, data_val, units)\n",
    "        \n",
    "        cycle.plot()\n",
    "        pd.DataFrame(rez.history)[[\"loss\", \"val_loss\"]].plot(figsize=(16, 8))\n",
    "        scores.append(min(rez.history[\"val_loss\"]))\n",
    "        \n",
    "        feat = yield_batch_test(data_val[0])\n",
    "        df = model.predict_generator(feat, steps=len(data_val[0].index.unique()))\n",
    "        df = scaler.inverse_transform(df)\n",
    "        y_oof.loc[ids_valid] = df\n",
    "        \n",
    "        feat = yield_batch_test(x_test)\n",
    "        df = model.predict_generator(feat, steps=len(x_test.index.unique()))\n",
    "        df = scaler.inverse_transform(df)\n",
    "        y_pred += df / FOLDS\n",
    "\n",
    "    print(f\"IOU на кроссвалидации: \" + str(-np.round(sorted(scores), 5)))\n",
    "    print(f\"IOU среднее: {-np.mean(scores):0.5f} +/- {np.std(scores):0.5f}\")\n",
    "\n",
    "    subdir = time.strftime('%Y-%m-%d_%H-%M')\n",
    "    path = pathlib.Path(f\"../processed/{subdir}\")\n",
    "    path.mkdir(exist_ok=True)\n",
    "    y_oof.to_csv(path / f\"oof-{-np.mean(scores):0.5f}.csv\", header=False)\n",
    "    y_pred.to_csv(path / f\"sub-{-np.mean(scores):0.5f}.csv\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold - 1 / 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 4)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 128)         35328     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 145,076\n",
      "Trainable params: 145,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.7494 - intersection_over_union: -0.0091 - val_loss: 0.6852 - val_intersection_over_union: -0.0228\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.1274 - val_loss: -0.1518\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.15178, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.6e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.2479 - val_loss: -0.2347\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.15178 to -0.23473, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.3e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.2863 - val_loss: -0.2910\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.23473 to -0.29095, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.9e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.3244 - val_loss: -0.3324\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.29095 to -0.33240, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 3.6e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.3671 - val_loss: -0.3783\n",
      "\n",
      "Epoch 00005: val_loss improved from -0.33240 to -0.37834, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 4.2e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4086 - val_loss: -0.4158\n",
      "\n",
      "Epoch 00006: val_loss improved from -0.37834 to -0.41576, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 4.9e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4315 - val_loss: -0.4408\n",
      "\n",
      "Epoch 00007: val_loss improved from -0.41576 to -0.44084, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 5.5e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4475 - val_loss: -0.4616\n",
      "\n",
      "Epoch 00008: val_loss improved from -0.44084 to -0.46159, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 6.2e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4634 - val_loss: -0.4723\n",
      "\n",
      "Epoch 00009: val_loss improved from -0.46159 to -0.47225, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 6.8e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4649 - val_loss: -0.4620\n",
      "\n",
      "Epoch 00010: val_loss did not improve from -0.47225\n",
      "\n",
      "Learning rate: 7.4e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4881 - val_loss: -0.5120\n",
      "\n",
      "Epoch 00011: val_loss improved from -0.47225 to -0.51203, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 8.1e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4783 - val_loss: -0.4875\n",
      "\n",
      "Epoch 00012: val_loss did not improve from -0.51203\n",
      "\n",
      "Learning rate: 8.7e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4887 - val_loss: -0.5079\n",
      "\n",
      "Epoch 00013: val_loss did not improve from -0.51203\n",
      "\n",
      "Learning rate: 9.4e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4902 - val_loss: -0.5085\n",
      "\n",
      "Epoch 00014: val_loss did not improve from -0.51203\n",
      "\n",
      "Learning rate: 1.0e-04\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5055 - val_loss: -0.5268\n",
      "\n",
      "Epoch 00015: val_loss improved from -0.51203 to -0.52679, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4869 - val_loss: -0.5270\n",
      "\n",
      "Epoch 00016: val_loss improved from -0.52679 to -0.52698, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4946 - val_loss: -0.5336\n",
      "\n",
      "Epoch 00017: val_loss improved from -0.52698 to -0.53361, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.2e-04\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4931 - val_loss: -0.5205\n",
      "\n",
      "Epoch 00018: val_loss did not improve from -0.53361\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5011 - val_loss: -0.5227\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -0.53361\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4910 - val_loss: -0.5242\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -0.53361\n",
      "\n",
      "Learning rate: 1.4e-04\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5076 - val_loss: -0.5339\n",
      "\n",
      "Epoch 00021: val_loss improved from -0.53361 to -0.53394, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4944 - val_loss: -0.5154\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -0.53394\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4945 - val_loss: -0.5385\n",
      "\n",
      "Epoch 00023: val_loss improved from -0.53394 to -0.53855, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4957 - val_loss: -0.5491\n",
      "\n",
      "Epoch 00024: val_loss improved from -0.53855 to -0.54905, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4862 - val_loss: -0.5232\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 1.7e-04\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4905 - val_loss: -0.5421\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5014 - val_loss: -0.5369\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5053 - val_loss: -0.5054\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 1.9e-04\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4989 - val_loss: -0.5081\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4897 - val_loss: -0.4989\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5045 - val_loss: -0.5365\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.1e-04\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5104 - val_loss: -0.5386\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5112 - val_loss: -0.5051\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5090 - val_loss: -0.5252\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.3e-04\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5023 - val_loss: -0.5335\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5087 - val_loss: -0.5262\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4867 - val_loss: -0.4985\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5166 - val_loss: -0.5479\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4909 - val_loss: -0.5226\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.6e-04\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5141 - val_loss: -0.5205\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4932 - val_loss: -0.5084\n",
      "\n",
      "Epoch 00041: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5162 - val_loss: -0.5345\n",
      "\n",
      "Epoch 00042: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.8e-04\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5035 - val_loss: -0.5419\n",
      "\n",
      "Epoch 00043: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5015 - val_loss: -0.5303\n",
      "\n",
      "Epoch 00044: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5098 - val_loss: -0.5251\n",
      "\n",
      "Epoch 00045: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 3.0e-04\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4917 - val_loss: -0.5074\n",
      "\n",
      "Epoch 00046: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5144 - val_loss: -0.5304\n",
      "\n",
      "Epoch 00047: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5075 - val_loss: -0.5299\n",
      "\n",
      "Epoch 00048: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.8e-04\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5140 - val_loss: -0.4843\n",
      "\n",
      "Epoch 00049: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5147 - val_loss: -0.5219\n",
      "\n",
      "Epoch 00050: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5313 - val_loss: -0.5457\n",
      "\n",
      "Epoch 00051: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.6e-04\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5190 - val_loss: -0.5348\n",
      "\n",
      "Epoch 00052: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5269 - val_loss: -0.5271\n",
      "\n",
      "Epoch 00053: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5194 - val_loss: -0.5150\n",
      "\n",
      "Epoch 00054: val_loss did not improve from -0.54905\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5353 - val_loss: -0.5508\n",
      "\n",
      "Epoch 00055: val_loss improved from -0.54905 to -0.55085, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5273 - val_loss: -0.5537\n",
      "\n",
      "Epoch 00056: val_loss improved from -0.55085 to -0.55370, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.3e-04\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5463 - val_loss: -0.5321\n",
      "\n",
      "Epoch 00057: val_loss did not improve from -0.55370\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5418 - val_loss: -0.5475\n",
      "\n",
      "Epoch 00058: val_loss did not improve from -0.55370\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5336 - val_loss: -0.5471\n",
      "\n",
      "Epoch 00059: val_loss did not improve from -0.55370\n",
      "\n",
      "Learning rate: 2.1e-04\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5521 - val_loss: -0.5536\n",
      "\n",
      "Epoch 00060: val_loss did not improve from -0.55370\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5368 - val_loss: -0.5448\n",
      "\n",
      "Epoch 00061: val_loss did not improve from -0.55370\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5454 - val_loss: -0.5357\n",
      "\n",
      "Epoch 00062: val_loss did not improve from -0.55370\n",
      "\n",
      "Learning rate: 1.9e-04\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5571 - val_loss: -0.5658\n",
      "\n",
      "Epoch 00063: val_loss improved from -0.55370 to -0.56580, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5529 - val_loss: -0.5458\n",
      "\n",
      "Epoch 00064: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5570 - val_loss: -0.5359\n",
      "\n",
      "Epoch 00065: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 1.7e-04\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5555 - val_loss: -0.5521\n",
      "\n",
      "Epoch 00066: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5547 - val_loss: -0.5524\n",
      "\n",
      "Epoch 00067: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5587 - val_loss: -0.5321\n",
      "\n",
      "Epoch 00068: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5604 - val_loss: -0.5602\n",
      "\n",
      "Epoch 00069: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5708 - val_loss: -0.5612\n",
      "\n",
      "Epoch 00070: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 1.4e-04\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5632 - val_loss: -0.5516\n",
      "\n",
      "Epoch 00071: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5669 - val_loss: -0.5579\n",
      "\n",
      "Epoch 00072: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5731 - val_loss: -0.5483\n",
      "\n",
      "Epoch 00073: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 1.2e-04\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: -0.5708 - val_loss: -0.5433\n",
      "\n",
      "Epoch 00074: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5786 - val_loss: -0.5614\n",
      "\n",
      "Epoch 00075: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5732 - val_loss: -0.5657\n",
      "\n",
      "Epoch 00076: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 1.0e-04\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5799 - val_loss: -0.5641\n",
      "\n",
      "Epoch 00077: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 9.4e-05\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5875 - val_loss: -0.5521\n",
      "\n",
      "Epoch 00078: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 8.7e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5917 - val_loss: -0.5595\n",
      "\n",
      "Epoch 00079: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 8.1e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5943 - val_loss: -0.5617\n",
      "\n",
      "Epoch 00080: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 7.4e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5910 - val_loss: -0.5647\n",
      "\n",
      "Epoch 00081: val_loss did not improve from -0.56580\n",
      "\n",
      "Learning rate: 6.8e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5937 - val_loss: -0.5668\n",
      "\n",
      "Epoch 00082: val_loss improved from -0.56580 to -0.56682, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 6.2e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6036 - val_loss: -0.5667\n",
      "\n",
      "Epoch 00083: val_loss did not improve from -0.56682\n",
      "\n",
      "Learning rate: 5.5e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5947 - val_loss: -0.5653\n",
      "\n",
      "Epoch 00084: val_loss did not improve from -0.56682\n",
      "\n",
      "Learning rate: 4.9e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6015 - val_loss: -0.5676\n",
      "\n",
      "Epoch 00085: val_loss improved from -0.56682 to -0.56759, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 4.2e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6015 - val_loss: -0.5699\n",
      "\n",
      "Epoch 00086: val_loss improved from -0.56759 to -0.56991, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 3.6e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6054 - val_loss: -0.5714\n",
      "\n",
      "Epoch 00087: val_loss improved from -0.56991 to -0.57143, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.9e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5977 - val_loss: -0.5693\n",
      "\n",
      "Epoch 00088: val_loss did not improve from -0.57143\n",
      "\n",
      "Learning rate: 2.3e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6127 - val_loss: -0.5736\n",
      "\n",
      "Epoch 00089: val_loss improved from -0.57143 to -0.57358, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.6e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6132 - val_loss: -0.5737\n",
      "\n",
      "Epoch 00090: val_loss improved from -0.57358 to -0.57367, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.0e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6186 - val_loss: -0.5724\n",
      "\n",
      "Epoch 00091: val_loss did not improve from -0.57367\n",
      "\n",
      "Learning rate: 6.3e-06\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6152 - val_loss: -0.5724\n",
      "\n",
      "Epoch 00092: val_loss did not improve from -0.57367\n",
      "\n",
      "Learning rate: 4.0e-06\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6081 - val_loss: -0.5716\n",
      "\n",
      "Epoch 00093: val_loss did not improve from -0.57367\n",
      "\n",
      "Learning rate: 2.5e-06\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6274 - val_loss: -0.5724\n",
      "\n",
      "Epoch 00094: val_loss did not improve from -0.57367\n",
      "\n",
      "Learning rate: 1.6e-06\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6202 - val_loss: -0.5726\n",
      "\n",
      "Epoch 00095: val_loss did not improve from -0.57367\n",
      "\n",
      "Learning rate: 1.0e-06\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6200 - val_loss: -0.5729\n",
      "\n",
      "Epoch 00096: val_loss did not improve from -0.57367\n",
      "\n",
      "Learning rate: 6.3e-07\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6174 - val_loss: -0.5731\n",
      "\n",
      "Epoch 00097: val_loss did not improve from -0.57367\n",
      "\n",
      "Learning rate: 4.0e-07\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6234 - val_loss: -0.5729\n",
      "\n",
      "Epoch 00098: val_loss did not improve from -0.57367\n",
      "\n",
      "Learning rate: 2.5e-07\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6140 - val_loss: -0.5728\n",
      "\n",
      "Epoch 00099: val_loss did not improve from -0.57367\n",
      "\n",
      "Learning rate: 1.6e-07\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6047 - val_loss: -0.5728\n",
      "\n",
      "Epoch 00100: val_loss did not improve from -0.57367\n",
      "\n",
      "Learning rate: 1.0e-07\n",
      "\n",
      "Fold - 2 / 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 4)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 128)         35328     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 145,076\n",
      "Trainable params: 145,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.7784 - intersection_over_union: -0.0020 - val_loss: 0.7553 - val_intersection_over_union: -0.0085\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: -0.0669 - val_loss: -0.0868\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.08685, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.6e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.1436 - val_loss: -0.1376\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.08685 to -0.13764, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.3e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.2108 - val_loss: -0.1988\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.13764 to -0.19884, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.9e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.2820 - val_loss: -0.2685\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.19884 to -0.26855, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 3.6e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.3378 - val_loss: -0.3261\n",
      "\n",
      "Epoch 00005: val_loss improved from -0.26855 to -0.32606, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 4.2e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.3708 - val_loss: -0.3689\n",
      "\n",
      "Epoch 00006: val_loss improved from -0.32606 to -0.36888, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 4.9e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.4078 - val_loss: -0.3987\n",
      "\n",
      "Epoch 00007: val_loss improved from -0.36888 to -0.39871, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 5.5e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4304 - val_loss: -0.4234\n",
      "\n",
      "Epoch 00008: val_loss improved from -0.39871 to -0.42335, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 6.2e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.4472 - val_loss: -0.4475\n",
      "\n",
      "Epoch 00009: val_loss improved from -0.42335 to -0.44751, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 6.8e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4701 - val_loss: -0.4681\n",
      "\n",
      "Epoch 00010: val_loss improved from -0.44751 to -0.46814, saving model to ../processed/model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning rate: 7.4e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.4756 - val_loss: -0.4757\n",
      "\n",
      "Epoch 00011: val_loss improved from -0.46814 to -0.47568, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 8.1e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4704 - val_loss: -0.4816\n",
      "\n",
      "Epoch 00012: val_loss improved from -0.47568 to -0.48163, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 8.7e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4852 - val_loss: -0.4945\n",
      "\n",
      "Epoch 00013: val_loss improved from -0.48163 to -0.49449, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 9.4e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4757 - val_loss: -0.5127\n",
      "\n",
      "Epoch 00014: val_loss improved from -0.49449 to -0.51266, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.0e-04\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4949 - val_loss: -0.5012\n",
      "\n",
      "Epoch 00015: val_loss did not improve from -0.51266\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5017 - val_loss: -0.4889\n",
      "\n",
      "Epoch 00016: val_loss did not improve from -0.51266\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.4966 - val_loss: -0.4836\n",
      "\n",
      "Epoch 00017: val_loss did not improve from -0.51266\n",
      "\n",
      "Learning rate: 1.2e-04\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5034 - val_loss: -0.4648\n",
      "\n",
      "Epoch 00018: val_loss did not improve from -0.51266\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5020 - val_loss: -0.5208\n",
      "\n",
      "Epoch 00019: val_loss improved from -0.51266 to -0.52084, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5076 - val_loss: -0.5108\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -0.52084\n",
      "\n",
      "Learning rate: 1.4e-04\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4905 - val_loss: -0.4931\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -0.52084\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5035 - val_loss: -0.5237\n",
      "\n",
      "Epoch 00022: val_loss improved from -0.52084 to -0.52365, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5090 - val_loss: -0.5106\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -0.52365\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4929 - val_loss: -0.5103\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -0.52365\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4988 - val_loss: -0.5176\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -0.52365\n",
      "\n",
      "Learning rate: 1.7e-04\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5004 - val_loss: -0.5104\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -0.52365\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5086 - val_loss: -0.5055\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -0.52365\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5050 - val_loss: -0.4633\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -0.52365\n",
      "\n",
      "Learning rate: 1.9e-04\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5057 - val_loss: -0.5325\n",
      "\n",
      "Epoch 00029: val_loss improved from -0.52365 to -0.53247, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5061 - val_loss: -0.5115\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -0.53247\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5190 - val_loss: -0.5082\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -0.53247\n",
      "\n",
      "Learning rate: 2.1e-04\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5201 - val_loss: -0.5137\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -0.53247\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5133 - val_loss: -0.5062\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -0.53247\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5017 - val_loss: -0.5102\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -0.53247\n",
      "\n",
      "Learning rate: 2.3e-04\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5119 - val_loss: -0.5149\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -0.53247\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5151 - val_loss: -0.5202\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -0.53247\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5091 - val_loss: -0.5006\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -0.53247\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5009 - val_loss: -0.5229\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -0.53247\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4953 - val_loss: -0.5292\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -0.53247\n",
      "\n",
      "Learning rate: 2.6e-04\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5065 - val_loss: -0.4960\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -0.53247\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4893 - val_loss: -0.5197\n",
      "\n",
      "Epoch 00041: val_loss did not improve from -0.53247\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5066 - val_loss: -0.5319\n",
      "\n",
      "Epoch 00042: val_loss did not improve from -0.53247\n",
      "\n",
      "Learning rate: 2.8e-04\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5111 - val_loss: -0.5372\n",
      "\n",
      "Epoch 00043: val_loss improved from -0.53247 to -0.53720, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5096 - val_loss: -0.5110\n",
      "\n",
      "Epoch 00044: val_loss did not improve from -0.53720\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5092 - val_loss: -0.4801\n",
      "\n",
      "Epoch 00045: val_loss did not improve from -0.53720\n",
      "\n",
      "Learning rate: 3.0e-04\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5097 - val_loss: -0.5376\n",
      "\n",
      "Epoch 00046: val_loss improved from -0.53720 to -0.53760, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5045 - val_loss: -0.5334\n",
      "\n",
      "Epoch 00047: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4965 - val_loss: -0.5095\n",
      "\n",
      "Epoch 00048: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.8e-04\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5155 - val_loss: -0.5206\n",
      "\n",
      "Epoch 00049: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5304 - val_loss: -0.5233\n",
      "\n",
      "Epoch 00050: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5276 - val_loss: -0.5226\n",
      "\n",
      "Epoch 00051: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.6e-04\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5114 - val_loss: -0.5240\n",
      "\n",
      "Epoch 00052: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5363 - val_loss: -0.5361\n",
      "\n",
      "Epoch 00053: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5157 - val_loss: -0.5172\n",
      "\n",
      "Epoch 00054: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5289 - val_loss: -0.5336\n",
      "\n",
      "Epoch 00055: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5330 - val_loss: -0.5256\n",
      "\n",
      "Epoch 00056: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.3e-04\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5329 - val_loss: -0.5281\n",
      "\n",
      "Epoch 00057: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5465 - val_loss: -0.5309\n",
      "\n",
      "Epoch 00058: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5373 - val_loss: -0.5364\n",
      "\n",
      "Epoch 00059: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.1e-04\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5404 - val_loss: -0.5056\n",
      "\n",
      "Epoch 00060: val_loss did not improve from -0.53760\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5435 - val_loss: -0.5470\n",
      "\n",
      "Epoch 00061: val_loss improved from -0.53760 to -0.54703, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5367 - val_loss: -0.5491\n",
      "\n",
      "Epoch 00062: val_loss improved from -0.54703 to -0.54911, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.9e-04\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5377 - val_loss: -0.5500\n",
      "\n",
      "Epoch 00063: val_loss improved from -0.54911 to -0.55002, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5427 - val_loss: -0.5552\n",
      "\n",
      "Epoch 00064: val_loss improved from -0.55002 to -0.55519, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5443 - val_loss: -0.5480\n",
      "\n",
      "Epoch 00065: val_loss did not improve from -0.55519\n",
      "\n",
      "Learning rate: 1.7e-04\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5601 - val_loss: -0.5506\n",
      "\n",
      "Epoch 00066: val_loss did not improve from -0.55519\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5451 - val_loss: -0.5342\n",
      "\n",
      "Epoch 00067: val_loss did not improve from -0.55519\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5591 - val_loss: -0.5504\n",
      "\n",
      "Epoch 00068: val_loss did not improve from -0.55519\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5660 - val_loss: -0.5503\n",
      "\n",
      "Epoch 00069: val_loss did not improve from -0.55519\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5640 - val_loss: -0.5506\n",
      "\n",
      "Epoch 00070: val_loss did not improve from -0.55519\n",
      "\n",
      "Learning rate: 1.4e-04\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5675 - val_loss: -0.5413\n",
      "\n",
      "Epoch 00071: val_loss did not improve from -0.55519\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5568 - val_loss: -0.5460\n",
      "\n",
      "Epoch 00072: val_loss did not improve from -0.55519\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5732 - val_loss: -0.5543\n",
      "\n",
      "Epoch 00073: val_loss did not improve from -0.55519\n",
      "\n",
      "Learning rate: 1.2e-04\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5805 - val_loss: -0.5522\n",
      "\n",
      "Epoch 00074: val_loss did not improve from -0.55519\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5799 - val_loss: -0.5418\n",
      "\n",
      "Epoch 00075: val_loss did not improve from -0.55519\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5729 - val_loss: -0.5437\n",
      "\n",
      "Epoch 00076: val_loss did not improve from -0.55519\n",
      "\n",
      "Learning rate: 1.0e-04\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5703 - val_loss: -0.5490\n",
      "\n",
      "Epoch 00077: val_loss did not improve from -0.55519\n",
      "\n",
      "Learning rate: 9.4e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5873 - val_loss: -0.5580\n",
      "\n",
      "Epoch 00078: val_loss improved from -0.55519 to -0.55805, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 8.7e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5760 - val_loss: -0.5568\n",
      "\n",
      "Epoch 00079: val_loss did not improve from -0.55805\n",
      "\n",
      "Learning rate: 8.1e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5802 - val_loss: -0.5552\n",
      "\n",
      "Epoch 00080: val_loss did not improve from -0.55805\n",
      "\n",
      "Learning rate: 7.4e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5936 - val_loss: -0.5575\n",
      "\n",
      "Epoch 00081: val_loss did not improve from -0.55805\n",
      "\n",
      "Learning rate: 6.8e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5933 - val_loss: -0.5527\n",
      "\n",
      "Epoch 00082: val_loss did not improve from -0.55805\n",
      "\n",
      "Learning rate: 6.2e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.5977 - val_loss: -0.5535\n",
      "\n",
      "Epoch 00083: val_loss did not improve from -0.55805\n",
      "\n",
      "Learning rate: 5.5e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5939 - val_loss: -0.5533\n",
      "\n",
      "Epoch 00084: val_loss did not improve from -0.55805\n",
      "\n",
      "Learning rate: 4.9e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5969 - val_loss: -0.5555\n",
      "\n",
      "Epoch 00085: val_loss did not improve from -0.55805\n",
      "\n",
      "Learning rate: 4.2e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5954 - val_loss: -0.5523\n",
      "\n",
      "Epoch 00086: val_loss did not improve from -0.55805\n",
      "\n",
      "Learning rate: 3.6e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 727s 727ms/step - loss: -0.5937 - val_loss: -0.5552\n",
      "\n",
      "Epoch 00087: val_loss did not improve from -0.55805\n",
      "\n",
      "Learning rate: 2.9e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5896 - val_loss: -0.5561\n",
      "\n",
      "Epoch 00088: val_loss did not improve from -0.55805\n",
      "\n",
      "Learning rate: 2.3e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5978 - val_loss: -0.5572\n",
      "\n",
      "Epoch 00089: val_loss did not improve from -0.55805\n",
      "\n",
      "Learning rate: 1.6e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6149 - val_loss: -0.5584\n",
      "\n",
      "Epoch 00090: val_loss improved from -0.55805 to -0.55844, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.0e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6006 - val_loss: -0.5597\n",
      "\n",
      "Epoch 00091: val_loss improved from -0.55844 to -0.55968, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 6.3e-06\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6104 - val_loss: -0.5584\n",
      "\n",
      "Epoch 00092: val_loss did not improve from -0.55968\n",
      "\n",
      "Learning rate: 4.0e-06\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6104 - val_loss: -0.5593\n",
      "\n",
      "Epoch 00093: val_loss did not improve from -0.55968\n",
      "\n",
      "Learning rate: 2.5e-06\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6058 - val_loss: -0.5603\n",
      "\n",
      "Epoch 00094: val_loss improved from -0.55968 to -0.56033, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.6e-06\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6090 - val_loss: -0.5601\n",
      "\n",
      "Epoch 00095: val_loss did not improve from -0.56033\n",
      "\n",
      "Learning rate: 1.0e-06\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6111 - val_loss: -0.5600\n",
      "\n",
      "Epoch 00096: val_loss did not improve from -0.56033\n",
      "\n",
      "Learning rate: 6.3e-07\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6025 - val_loss: -0.5598\n",
      "\n",
      "Epoch 00097: val_loss did not improve from -0.56033\n",
      "\n",
      "Learning rate: 4.0e-07\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6089 - val_loss: -0.5597\n",
      "\n",
      "Epoch 00098: val_loss did not improve from -0.56033\n",
      "\n",
      "Learning rate: 2.5e-07\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6040 - val_loss: -0.5597\n",
      "\n",
      "Epoch 00099: val_loss did not improve from -0.56033\n",
      "\n",
      "Learning rate: 1.6e-07\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6086 - val_loss: -0.5597\n",
      "\n",
      "Epoch 00100: val_loss did not improve from -0.56033\n",
      "\n",
      "Learning rate: 1.0e-07\n",
      "\n",
      "Fold - 3 / 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 4)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 128)         35328     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 145,076\n",
      "Trainable params: 145,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.7554 - intersection_over_union: -0.0064 - val_loss: 0.7179 - val_intersection_over_union: -0.0200\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: -0.1032 - val_loss: -0.1422\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.14216, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.6e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.2011 - val_loss: -0.2075\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.14216 to -0.20745, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.3e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.2741 - val_loss: -0.2606\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.20745 to -0.26064, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.9e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.3314 - val_loss: -0.3021\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.26064 to -0.30214, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 3.6e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.3712 - val_loss: -0.3557\n",
      "\n",
      "Epoch 00005: val_loss improved from -0.30214 to -0.35570, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 4.2e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4016 - val_loss: -0.3970\n",
      "\n",
      "Epoch 00006: val_loss improved from -0.35570 to -0.39702, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 4.9e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4418 - val_loss: -0.4193\n",
      "\n",
      "Epoch 00007: val_loss improved from -0.39702 to -0.41929, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 5.5e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4605 - val_loss: -0.4248\n",
      "\n",
      "Epoch 00008: val_loss improved from -0.41929 to -0.42483, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 6.2e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4916 - val_loss: -0.4496\n",
      "\n",
      "Epoch 00009: val_loss improved from -0.42483 to -0.44962, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 6.8e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4996 - val_loss: -0.4757\n",
      "\n",
      "Epoch 00010: val_loss improved from -0.44962 to -0.47570, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 7.4e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.4917 - val_loss: -0.4605\n",
      "\n",
      "Epoch 00011: val_loss did not improve from -0.47570\n",
      "\n",
      "Learning rate: 8.1e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5074 - val_loss: -0.4817\n",
      "\n",
      "Epoch 00012: val_loss improved from -0.47570 to -0.48169, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 8.7e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5081 - val_loss: -0.4866\n",
      "\n",
      "Epoch 00013: val_loss improved from -0.48169 to -0.48664, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 9.4e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5075 - val_loss: -0.4405\n",
      "\n",
      "Epoch 00014: val_loss did not improve from -0.48664\n",
      "\n",
      "Learning rate: 1.0e-04\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5008 - val_loss: -0.4979\n",
      "\n",
      "Epoch 00015: val_loss improved from -0.48664 to -0.49793, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5180 - val_loss: -0.4859\n",
      "\n",
      "Epoch 00016: val_loss did not improve from -0.49793\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5007 - val_loss: -0.4765\n",
      "\n",
      "Epoch 00017: val_loss did not improve from -0.49793\n",
      "\n",
      "Learning rate: 1.2e-04\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5266 - val_loss: -0.4827\n",
      "\n",
      "Epoch 00018: val_loss did not improve from -0.49793\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5118 - val_loss: -0.5003\n",
      "\n",
      "Epoch 00019: val_loss improved from -0.49793 to -0.50027, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: -0.5124 - val_loss: -0.4845\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -0.50027\n",
      "\n",
      "Learning rate: 1.4e-04\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5179 - val_loss: -0.4857\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -0.50027\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5200 - val_loss: -0.4838\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -0.50027\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5164 - val_loss: -0.4766\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -0.50027\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5117 - val_loss: -0.4880\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -0.50027\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5032 - val_loss: -0.4879\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -0.50027\n",
      "\n",
      "Learning rate: 1.7e-04\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5181 - val_loss: -0.4651\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -0.50027\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5144 - val_loss: -0.5000\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -0.50027\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5166 - val_loss: -0.4924\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -0.50027\n",
      "\n",
      "Learning rate: 1.9e-04\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5129 - val_loss: -0.4914\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -0.50027\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5047 - val_loss: -0.4862\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -0.50027\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5284 - val_loss: -0.5062\n",
      "\n",
      "Epoch 00031: val_loss improved from -0.50027 to -0.50620, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.1e-04\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5316 - val_loss: -0.4724\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5269 - val_loss: -0.4842\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5221 - val_loss: -0.4892\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.3e-04\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5138 - val_loss: -0.4518\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5153 - val_loss: -0.4825\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5188 - val_loss: -0.5040\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5214 - val_loss: -0.4642\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5179 - val_loss: -0.4897\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.6e-04\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5141 - val_loss: -0.5057\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5092 - val_loss: -0.5054\n",
      "\n",
      "Epoch 00041: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5221 - val_loss: -0.5032\n",
      "\n",
      "Epoch 00042: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.8e-04\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5011 - val_loss: -0.5049\n",
      "\n",
      "Epoch 00043: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5061 - val_loss: -0.4901\n",
      "\n",
      "Epoch 00044: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5321 - val_loss: -0.5011\n",
      "\n",
      "Epoch 00045: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 3.0e-04\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5084 - val_loss: -0.4924\n",
      "\n",
      "Epoch 00046: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5209 - val_loss: -0.4845\n",
      "\n",
      "Epoch 00047: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5351 - val_loss: -0.4907\n",
      "\n",
      "Epoch 00048: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.8e-04\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5256 - val_loss: -0.4978\n",
      "\n",
      "Epoch 00049: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5207 - val_loss: -0.4948\n",
      "\n",
      "Epoch 00050: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5223 - val_loss: -0.4944\n",
      "\n",
      "Epoch 00051: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.6e-04\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5291 - val_loss: -0.4925\n",
      "\n",
      "Epoch 00052: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5300 - val_loss: -0.4868\n",
      "\n",
      "Epoch 00053: val_loss did not improve from -0.50620\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: -0.5309 - val_loss: -0.5137\n",
      "\n",
      "Epoch 00054: val_loss improved from -0.50620 to -0.51371, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: -0.5309 - val_loss: -0.5002\n",
      "\n",
      "Epoch 00055: val_loss did not improve from -0.51371\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5300 - val_loss: -0.4918\n",
      "\n",
      "Epoch 00056: val_loss did not improve from -0.51371\n",
      "\n",
      "Learning rate: 2.3e-04\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 2387s 2s/step - loss: -0.5426 - val_loss: -0.5183\n",
      "\n",
      "Epoch 00057: val_loss improved from -0.51371 to -0.51834, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5395 - val_loss: -0.5062\n",
      "\n",
      "Epoch 00058: val_loss did not improve from -0.51834\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: -0.5583 - val_loss: -0.5141\n",
      "\n",
      "Epoch 00059: val_loss did not improve from -0.51834\n",
      "\n",
      "Learning rate: 2.1e-04\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5553 - val_loss: -0.5196\n",
      "\n",
      "Epoch 00060: val_loss improved from -0.51834 to -0.51962, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5399 - val_loss: -0.5066\n",
      "\n",
      "Epoch 00061: val_loss did not improve from -0.51962\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5472 - val_loss: -0.5130\n",
      "\n",
      "Epoch 00062: val_loss did not improve from -0.51962\n",
      "\n",
      "Learning rate: 1.9e-04\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5505 - val_loss: -0.4971\n",
      "\n",
      "Epoch 00063: val_loss did not improve from -0.51962\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: -0.5514 - val_loss: -0.5107\n",
      "\n",
      "Epoch 00064: val_loss did not improve from -0.51962\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: -0.5691 - val_loss: -0.5049\n",
      "\n",
      "Epoch 00065: val_loss did not improve from -0.51962\n",
      "\n",
      "Learning rate: 1.7e-04\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: -0.5586 - val_loss: -0.5213\n",
      "\n",
      "Epoch 00066: val_loss improved from -0.51962 to -0.52132, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: -0.5653 - val_loss: -0.5135\n",
      "\n",
      "Epoch 00067: val_loss did not improve from -0.52132\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: -0.5614 - val_loss: -0.5194\n",
      "\n",
      "Epoch 00068: val_loss did not improve from -0.52132\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: -0.5660 - val_loss: -0.5218\n",
      "\n",
      "Epoch 00069: val_loss improved from -0.52132 to -0.52179, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: -0.5765 - val_loss: -0.5204\n",
      "\n",
      "Epoch 00070: val_loss did not improve from -0.52179\n",
      "\n",
      "Learning rate: 1.4e-04\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 17s 17ms/step - loss: -0.5619 - val_loss: -0.5145\n",
      "\n",
      "Epoch 00071: val_loss did not improve from -0.52179\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5680 - val_loss: -0.5246\n",
      "\n",
      "Epoch 00072: val_loss improved from -0.52179 to -0.52459, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5673 - val_loss: -0.5177\n",
      "\n",
      "Epoch 00073: val_loss did not improve from -0.52459\n",
      "\n",
      "Learning rate: 1.2e-04\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5793 - val_loss: -0.5202\n",
      "\n",
      "Epoch 00074: val_loss did not improve from -0.52459\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5848 - val_loss: -0.5296\n",
      "\n",
      "Epoch 00075: val_loss improved from -0.52459 to -0.52960, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5759 - val_loss: -0.5188\n",
      "\n",
      "Epoch 00076: val_loss did not improve from -0.52960\n",
      "\n",
      "Learning rate: 1.0e-04\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5869 - val_loss: -0.5294\n",
      "\n",
      "Epoch 00077: val_loss did not improve from -0.52960\n",
      "\n",
      "Learning rate: 9.4e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5935 - val_loss: -0.5126\n",
      "\n",
      "Epoch 00078: val_loss did not improve from -0.52960\n",
      "\n",
      "Learning rate: 8.7e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5840 - val_loss: -0.5270\n",
      "\n",
      "Epoch 00079: val_loss did not improve from -0.52960\n",
      "\n",
      "Learning rate: 8.1e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5944 - val_loss: -0.5286\n",
      "\n",
      "Epoch 00080: val_loss did not improve from -0.52960\n",
      "\n",
      "Learning rate: 7.4e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6045 - val_loss: -0.5283\n",
      "\n",
      "Epoch 00081: val_loss did not improve from -0.52960\n",
      "\n",
      "Learning rate: 6.8e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6029 - val_loss: -0.5292\n",
      "\n",
      "Epoch 00082: val_loss did not improve from -0.52960\n",
      "\n",
      "Learning rate: 6.2e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6055 - val_loss: -0.5356\n",
      "\n",
      "Epoch 00083: val_loss improved from -0.52960 to -0.53558, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 5.5e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6057 - val_loss: -0.5317\n",
      "\n",
      "Epoch 00084: val_loss did not improve from -0.53558\n",
      "\n",
      "Learning rate: 4.9e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6019 - val_loss: -0.5225\n",
      "\n",
      "Epoch 00085: val_loss did not improve from -0.53558\n",
      "\n",
      "Learning rate: 4.2e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6061 - val_loss: -0.5378\n",
      "\n",
      "Epoch 00086: val_loss improved from -0.53558 to -0.53780, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 3.6e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6053 - val_loss: -0.5355\n",
      "\n",
      "Epoch 00087: val_loss did not improve from -0.53780\n",
      "\n",
      "Learning rate: 2.9e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6120 - val_loss: -0.5405\n",
      "\n",
      "Epoch 00088: val_loss improved from -0.53780 to -0.54052, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.3e-05\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6183 - val_loss: -0.5390\n",
      "\n",
      "Epoch 00089: val_loss did not improve from -0.54052\n",
      "\n",
      "Learning rate: 1.6e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6149 - val_loss: -0.5413\n",
      "\n",
      "Epoch 00090: val_loss improved from -0.54052 to -0.54127, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.0e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6170 - val_loss: -0.5388\n",
      "\n",
      "Epoch 00091: val_loss did not improve from -0.54127\n",
      "\n",
      "Learning rate: 6.3e-06\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6156 - val_loss: -0.5418\n",
      "\n",
      "Epoch 00092: val_loss improved from -0.54127 to -0.54179, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 4.0e-06\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6159 - val_loss: -0.5420\n",
      "\n",
      "Epoch 00093: val_loss improved from -0.54179 to -0.54201, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.5e-06\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6198 - val_loss: -0.5418\n",
      "\n",
      "Epoch 00094: val_loss did not improve from -0.54201\n",
      "\n",
      "Learning rate: 1.6e-06\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6116 - val_loss: -0.5423\n",
      "\n",
      "Epoch 00095: val_loss improved from -0.54201 to -0.54227, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.0e-06\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6122 - val_loss: -0.5420\n",
      "\n",
      "Epoch 00096: val_loss did not improve from -0.54227\n",
      "\n",
      "Learning rate: 6.3e-07\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6227 - val_loss: -0.5418\n",
      "\n",
      "Epoch 00097: val_loss did not improve from -0.54227\n",
      "\n",
      "Learning rate: 4.0e-07\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.6179 - val_loss: -0.5419\n",
      "\n",
      "Epoch 00098: val_loss did not improve from -0.54227\n",
      "\n",
      "Learning rate: 2.5e-07\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 32s 32ms/step - loss: -0.6102 - val_loss: -0.5419\n",
      "\n",
      "Epoch 00099: val_loss did not improve from -0.54227\n",
      "\n",
      "Learning rate: 1.6e-07\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: -0.6117 - val_loss: -0.5419\n",
      "\n",
      "Epoch 00100: val_loss did not improve from -0.54227\n",
      "\n",
      "Learning rate: 1.0e-07\n",
      "\n",
      "Fold - 4 / 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 4)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 128)         35328     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 145,076\n",
      "Trainable params: 145,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.7403 - intersection_over_union: -0.0105 - val_loss: 0.6686 - val_intersection_over_union: -0.0344\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: -0.1084 - val_loss: -0.1452\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.14521, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.6e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.1723 - val_loss: -0.1871\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.14521 to -0.18707, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.3e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: -0.2309 - val_loss: -0.2406\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.18707 to -0.24057, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.9e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: -0.2806 - val_loss: -0.2880\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.24057 to -0.28803, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 3.6e-05\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 20s 20ms/step - loss: -0.3428 - val_loss: -0.3321\n",
      "\n",
      "Epoch 00005: val_loss improved from -0.28803 to -0.33207, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 4.2e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.3777 - val_loss: -0.3581\n",
      "\n",
      "Epoch 00006: val_loss improved from -0.33207 to -0.35806, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 4.9e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.4028 - val_loss: -0.3941\n",
      "\n",
      "Epoch 00007: val_loss improved from -0.35806 to -0.39409, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 5.5e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: -0.4555 - val_loss: -0.4122\n",
      "\n",
      "Epoch 00008: val_loss improved from -0.39409 to -0.41217, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 6.2e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.4697 - val_loss: -0.4368\n",
      "\n",
      "Epoch 00009: val_loss improved from -0.41217 to -0.43680, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 6.8e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: -0.4704 - val_loss: -0.4449\n",
      "\n",
      "Epoch 00010: val_loss improved from -0.43680 to -0.44489, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 7.4e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: -0.4803 - val_loss: -0.4455\n",
      "\n",
      "Epoch 00011: val_loss improved from -0.44489 to -0.44551, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 8.1e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.4857 - val_loss: -0.4487\n",
      "\n",
      "Epoch 00012: val_loss improved from -0.44551 to -0.44868, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 8.7e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.4874 - val_loss: -0.4620\n",
      "\n",
      "Epoch 00013: val_loss improved from -0.44868 to -0.46198, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 9.4e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.4833 - val_loss: -0.4617\n",
      "\n",
      "Epoch 00014: val_loss did not improve from -0.46198\n",
      "\n",
      "Learning rate: 1.0e-04\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: -0.4876 - val_loss: -0.4713\n",
      "\n",
      "Epoch 00015: val_loss improved from -0.46198 to -0.47132, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.4870 - val_loss: -0.4783\n",
      "\n",
      "Epoch 00016: val_loss improved from -0.47132 to -0.47828, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.5056 - val_loss: -0.4656\n",
      "\n",
      "Epoch 00017: val_loss did not improve from -0.47828\n",
      "\n",
      "Learning rate: 1.2e-04\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.5047 - val_loss: -0.4879\n",
      "\n",
      "Epoch 00018: val_loss improved from -0.47828 to -0.48790, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.5043 - val_loss: -0.4904\n",
      "\n",
      "Epoch 00019: val_loss improved from -0.48790 to -0.49043, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: -0.5093 - val_loss: -0.4816\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -0.49043\n",
      "\n",
      "Learning rate: 1.4e-04\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.5022 - val_loss: -0.4749\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -0.49043\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.5071 - val_loss: -0.5134\n",
      "\n",
      "Epoch 00022: val_loss improved from -0.49043 to -0.51337, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.5036 - val_loss: -0.4868\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.5083 - val_loss: -0.4833\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: -0.5217 - val_loss: -0.4849\n",
      "\n",
      "Epoch 00025: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 1.7e-04\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: -0.5133 - val_loss: -0.4954\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.5136 - val_loss: -0.4906\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.5103 - val_loss: -0.4835\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 1.9e-04\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.5087 - val_loss: -0.4776\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.5063 - val_loss: -0.4782\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.4996 - val_loss: -0.4578\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.1e-04\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.5123 - val_loss: -0.4938\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.5108 - val_loss: -0.4757\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: -0.5108 - val_loss: -0.5016\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.3e-04\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.5086 - val_loss: -0.4864\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.5156 - val_loss: -0.4985\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.5303 - val_loss: -0.4680\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.5105 - val_loss: -0.4618\n",
      "\n",
      "Epoch 00038: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.5203 - val_loss: -0.5007\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.6e-04\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: -0.5194 - val_loss: -0.4542\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: -0.5266 - val_loss: -0.4792\n",
      "\n",
      "Epoch 00041: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.5293 - val_loss: -0.5056\n",
      "\n",
      "Epoch 00042: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.8e-04\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.5151 - val_loss: -0.4957\n",
      "\n",
      "Epoch 00043: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: -0.5086 - val_loss: -0.4787\n",
      "\n",
      "Epoch 00044: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.5179 - val_loss: -0.4907\n",
      "\n",
      "Epoch 00045: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 3.0e-04\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 22s 22ms/step - loss: -0.5193 - val_loss: -0.4849\n",
      "\n",
      "Epoch 00046: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: -0.5050 - val_loss: -0.4886\n",
      "\n",
      "Epoch 00047: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 7220s 7s/step - loss: -0.5170 - val_loss: -0.5021\n",
      "\n",
      "Epoch 00048: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.8e-04\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5319 - val_loss: -0.4920\n",
      "\n",
      "Epoch 00049: val_loss did not improve from -0.51337\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5270 - val_loss: -0.5212\n",
      "\n",
      "Epoch 00050: val_loss improved from -0.51337 to -0.52120, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5320 - val_loss: -0.5028\n",
      "\n",
      "Epoch 00051: val_loss did not improve from -0.52120\n",
      "\n",
      "Learning rate: 2.6e-04\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5345 - val_loss: -0.5167\n",
      "\n",
      "Epoch 00052: val_loss did not improve from -0.52120\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5303 - val_loss: -0.4931\n",
      "\n",
      "Epoch 00053: val_loss did not improve from -0.52120\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5407 - val_loss: -0.4996\n",
      "\n",
      "Epoch 00054: val_loss did not improve from -0.52120\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5500 - val_loss: -0.4969\n",
      "\n",
      "Epoch 00055: val_loss did not improve from -0.52120\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5380 - val_loss: -0.4901\n",
      "\n",
      "Epoch 00056: val_loss did not improve from -0.52120\n",
      "\n",
      "Learning rate: 2.3e-04\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5489 - val_loss: -0.5089\n",
      "\n",
      "Epoch 00057: val_loss did not improve from -0.52120\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5470 - val_loss: -0.5083\n",
      "\n",
      "Epoch 00058: val_loss did not improve from -0.52120\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5524 - val_loss: -0.5055\n",
      "\n",
      "Epoch 00059: val_loss did not improve from -0.52120\n",
      "\n",
      "Learning rate: 2.1e-04\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5481 - val_loss: -0.5218\n",
      "\n",
      "Epoch 00060: val_loss improved from -0.52120 to -0.52185, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: -0.5660 - val_loss: -0.5194\n",
      "\n",
      "Epoch 00061: val_loss did not improve from -0.52185\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: -0.5574 - val_loss: -0.5122\n",
      "\n",
      "Epoch 00062: val_loss did not improve from -0.52185\n",
      "\n",
      "Learning rate: 1.9e-04\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5616 - val_loss: -0.5225\n",
      "\n",
      "Epoch 00063: val_loss improved from -0.52185 to -0.52253, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5621 - val_loss: -0.5079\n",
      "\n",
      "Epoch 00064: val_loss did not improve from -0.52253\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5675 - val_loss: -0.5133\n",
      "\n",
      "Epoch 00065: val_loss did not improve from -0.52253\n",
      "\n",
      "Learning rate: 1.7e-04\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5639 - val_loss: -0.5259\n",
      "\n",
      "Epoch 00066: val_loss improved from -0.52253 to -0.52591, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5621 - val_loss: -0.5146\n",
      "\n",
      "Epoch 00067: val_loss did not improve from -0.52591\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5663 - val_loss: -0.5158\n",
      "\n",
      "Epoch 00068: val_loss did not improve from -0.52591\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5704 - val_loss: -0.5205\n",
      "\n",
      "Epoch 00069: val_loss did not improve from -0.52591\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5687 - val_loss: -0.5179\n",
      "\n",
      "Epoch 00070: val_loss did not improve from -0.52591\n",
      "\n",
      "Learning rate: 1.4e-04\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5746 - val_loss: -0.5214\n",
      "\n",
      "Epoch 00071: val_loss did not improve from -0.52591\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5742 - val_loss: -0.5096\n",
      "\n",
      "Epoch 00072: val_loss did not improve from -0.52591\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5747 - val_loss: -0.5133\n",
      "\n",
      "Epoch 00073: val_loss did not improve from -0.52591\n",
      "\n",
      "Learning rate: 1.2e-04\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5774 - val_loss: -0.5197\n",
      "\n",
      "Epoch 00074: val_loss did not improve from -0.52591\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5846 - val_loss: -0.5261\n",
      "\n",
      "Epoch 00075: val_loss improved from -0.52591 to -0.52608, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5880 - val_loss: -0.5211\n",
      "\n",
      "Epoch 00076: val_loss did not improve from -0.52608\n",
      "\n",
      "Learning rate: 1.0e-04\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5860 - val_loss: -0.5194\n",
      "\n",
      "Epoch 00077: val_loss did not improve from -0.52608\n",
      "\n",
      "Learning rate: 9.4e-05\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5969 - val_loss: -0.5187\n",
      "\n",
      "Epoch 00078: val_loss did not improve from -0.52608\n",
      "\n",
      "Learning rate: 8.7e-05\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5939 - val_loss: -0.5200\n",
      "\n",
      "Epoch 00079: val_loss did not improve from -0.52608\n",
      "\n",
      "Learning rate: 8.1e-05\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5918 - val_loss: -0.5204\n",
      "\n",
      "Epoch 00080: val_loss did not improve from -0.52608\n",
      "\n",
      "Learning rate: 7.4e-05\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6024 - val_loss: -0.5205\n",
      "\n",
      "Epoch 00081: val_loss did not improve from -0.52608\n",
      "\n",
      "Learning rate: 6.8e-05\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5969 - val_loss: -0.5184\n",
      "\n",
      "Epoch 00082: val_loss did not improve from -0.52608\n",
      "\n",
      "Learning rate: 6.2e-05\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5932 - val_loss: -0.5208\n",
      "\n",
      "Epoch 00083: val_loss did not improve from -0.52608\n",
      "\n",
      "Learning rate: 5.5e-05\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.5898 - val_loss: -0.5260\n",
      "\n",
      "Epoch 00084: val_loss did not improve from -0.52608\n",
      "\n",
      "Learning rate: 4.9e-05\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6123 - val_loss: -0.5306\n",
      "\n",
      "Epoch 00085: val_loss improved from -0.52608 to -0.53059, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 4.2e-05\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6006 - val_loss: -0.5299\n",
      "\n",
      "Epoch 00086: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 3.6e-05\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6057 - val_loss: -0.5299\n",
      "\n",
      "Epoch 00087: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 2.9e-05\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6149 - val_loss: -0.5295\n",
      "\n",
      "Epoch 00088: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 2.3e-05\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6167 - val_loss: -0.5286\n",
      "\n",
      "Epoch 00089: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 1.6e-05\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6141 - val_loss: -0.5293\n",
      "\n",
      "Epoch 00090: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 1.0e-05\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6233 - val_loss: -0.5289\n",
      "\n",
      "Epoch 00091: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 6.3e-06\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6219 - val_loss: -0.5290\n",
      "\n",
      "Epoch 00092: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 4.0e-06\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6210 - val_loss: -0.5295\n",
      "\n",
      "Epoch 00093: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 2.5e-06\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6202 - val_loss: -0.5298\n",
      "\n",
      "Epoch 00094: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 1.6e-06\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6260 - val_loss: -0.5298\n",
      "\n",
      "Epoch 00095: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 1.0e-06\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6206 - val_loss: -0.5297\n",
      "\n",
      "Epoch 00096: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 6.3e-07\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6109 - val_loss: -0.5296\n",
      "\n",
      "Epoch 00097: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 4.0e-07\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 14s 14ms/step - loss: -0.6143 - val_loss: -0.5296\n",
      "\n",
      "Epoch 00098: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 2.5e-07\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6252 - val_loss: -0.5296\n",
      "\n",
      "Epoch 00099: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 1.6e-07\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.6237 - val_loss: -0.5296\n",
      "\n",
      "Epoch 00100: val_loss did not improve from -0.53059\n",
      "\n",
      "Learning rate: 1.0e-07\n",
      "\n",
      "Fold - 5 / 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 4)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 128)         35328     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 145,076\n",
      "Trainable params: 145,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.8057 - intersection_over_union: -9.5688e-04 - val_loss: 0.7434 - val_intersection_over_union: -0.0048\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: -0.0514 - val_loss: -0.0964\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.09637, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.6e-05\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.1280 - val_loss: -0.1203\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.09637 to -0.12030, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.3e-05\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.1327 - val_loss: -0.1415\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.12030 to -0.14150, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.9e-05\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.1600 - val_loss: -0.1769\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.14150 to -0.17692, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 3.6e-05\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.1822 - val_loss: -0.2020\n",
      "\n",
      "Epoch 00005: val_loss improved from -0.17692 to -0.20203, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 4.2e-05\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.2077 - val_loss: -0.2250\n",
      "\n",
      "Epoch 00006: val_loss improved from -0.20203 to -0.22503, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 4.9e-05\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.2418 - val_loss: -0.2395\n",
      "\n",
      "Epoch 00007: val_loss improved from -0.22503 to -0.23950, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 5.5e-05\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.2486 - val_loss: -0.2639\n",
      "\n",
      "Epoch 00008: val_loss improved from -0.23950 to -0.26395, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 6.2e-05\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.2799 - val_loss: -0.2913\n",
      "\n",
      "Epoch 00009: val_loss improved from -0.26395 to -0.29134, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 6.8e-05\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.2965 - val_loss: -0.3177\n",
      "\n",
      "Epoch 00010: val_loss improved from -0.29134 to -0.31772, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 7.4e-05\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.3380 - val_loss: -0.3427\n",
      "\n",
      "Epoch 00011: val_loss improved from -0.31772 to -0.34269, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 8.1e-05\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.3646 - val_loss: -0.3767\n",
      "\n",
      "Epoch 00012: val_loss improved from -0.34269 to -0.37667, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 8.7e-05\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.3887 - val_loss: -0.4029\n",
      "\n",
      "Epoch 00013: val_loss improved from -0.37667 to -0.40290, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 9.4e-05\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4274 - val_loss: -0.4435\n",
      "\n",
      "Epoch 00014: val_loss improved from -0.40290 to -0.44348, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.0e-04\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4617 - val_loss: -0.4557\n",
      "\n",
      "Epoch 00015: val_loss improved from -0.44348 to -0.45570, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4761 - val_loss: -0.4594\n",
      "\n",
      "Epoch 00016: val_loss improved from -0.45570 to -0.45939, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.1e-04\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4792 - val_loss: -0.4413\n",
      "\n",
      "Epoch 00017: val_loss did not improve from -0.45939\n",
      "\n",
      "Learning rate: 1.2e-04\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4766 - val_loss: -0.4763\n",
      "\n",
      "Epoch 00018: val_loss improved from -0.45939 to -0.47635, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5018 - val_loss: -0.4974\n",
      "\n",
      "Epoch 00019: val_loss improved from -0.47635 to -0.49740, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.3e-04\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5024 - val_loss: -0.5016\n",
      "\n",
      "Epoch 00020: val_loss improved from -0.49740 to -0.50161, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.4e-04\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5044 - val_loss: -0.4682\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -0.50161\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.4910 - val_loss: -0.4975\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -0.50161\n",
      "\n",
      "Learning rate: 1.5e-04\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5069 - val_loss: -0.5036\n",
      "\n",
      "Epoch 00023: val_loss improved from -0.50161 to -0.50359, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5218 - val_loss: -0.5028\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -0.50359\n",
      "\n",
      "Learning rate: 1.6e-04\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5009 - val_loss: -0.5097\n",
      "\n",
      "Epoch 00025: val_loss improved from -0.50359 to -0.50971, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 1.7e-04\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5080 - val_loss: -0.5048\n",
      "\n",
      "Epoch 00026: val_loss did not improve from -0.50971\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5060 - val_loss: -0.4974\n",
      "\n",
      "Epoch 00027: val_loss did not improve from -0.50971\n",
      "\n",
      "Learning rate: 1.8e-04\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5144 - val_loss: -0.5055\n",
      "\n",
      "Epoch 00028: val_loss did not improve from -0.50971\n",
      "\n",
      "Learning rate: 1.9e-04\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5074 - val_loss: -0.4963\n",
      "\n",
      "Epoch 00029: val_loss did not improve from -0.50971\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5131 - val_loss: -0.5044\n",
      "\n",
      "Epoch 00030: val_loss did not improve from -0.50971\n",
      "\n",
      "Learning rate: 2.0e-04\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5037 - val_loss: -0.5037\n",
      "\n",
      "Epoch 00031: val_loss did not improve from -0.50971\n",
      "\n",
      "Learning rate: 2.1e-04\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5033 - val_loss: -0.4870\n",
      "\n",
      "Epoch 00032: val_loss did not improve from -0.50971\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: -0.5078 - val_loss: -0.4564\n",
      "\n",
      "Epoch 00033: val_loss did not improve from -0.50971\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5099 - val_loss: -0.4882\n",
      "\n",
      "Epoch 00034: val_loss did not improve from -0.50971\n",
      "\n",
      "Learning rate: 2.3e-04\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5075 - val_loss: -0.5030\n",
      "\n",
      "Epoch 00035: val_loss did not improve from -0.50971\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5047 - val_loss: -0.4762\n",
      "\n",
      "Epoch 00036: val_loss did not improve from -0.50971\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5092 - val_loss: -0.4780\n",
      "\n",
      "Epoch 00037: val_loss did not improve from -0.50971\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5196 - val_loss: -0.5139\n",
      "\n",
      "Epoch 00038: val_loss improved from -0.50971 to -0.51390, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5192 - val_loss: -0.5092\n",
      "\n",
      "Epoch 00039: val_loss did not improve from -0.51390\n",
      "\n",
      "Learning rate: 2.6e-04\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5149 - val_loss: -0.4847\n",
      "\n",
      "Epoch 00040: val_loss did not improve from -0.51390\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5168 - val_loss: -0.4939\n",
      "\n",
      "Epoch 00041: val_loss did not improve from -0.51390\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: -0.5075 - val_loss: -0.4910\n",
      "\n",
      "Epoch 00042: val_loss did not improve from -0.51390\n",
      "\n",
      "Learning rate: 2.8e-04\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: -0.5215 - val_loss: -0.5109\n",
      "\n",
      "Epoch 00043: val_loss did not improve from -0.51390\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: -0.5053 - val_loss: -0.4992\n",
      "\n",
      "Epoch 00044: val_loss did not improve from -0.51390\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: -0.5089 - val_loss: -0.5101\n",
      "\n",
      "Epoch 00045: val_loss did not improve from -0.51390\n",
      "\n",
      "Learning rate: 3.0e-04\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: -0.5274 - val_loss: -0.4903\n",
      "\n",
      "Epoch 00046: val_loss did not improve from -0.51390\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: -0.5242 - val_loss: -0.5007\n",
      "\n",
      "Epoch 00047: val_loss did not improve from -0.51390\n",
      "\n",
      "Learning rate: 2.9e-04\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: -0.5165 - val_loss: -0.4995\n",
      "\n",
      "Epoch 00048: val_loss did not improve from -0.51390\n",
      "\n",
      "Learning rate: 2.8e-04\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: -0.5283 - val_loss: -0.5210\n",
      "\n",
      "Epoch 00049: val_loss improved from -0.51390 to -0.52102, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: -0.5208 - val_loss: -0.5052\n",
      "\n",
      "Epoch 00050: val_loss did not improve from -0.52102\n",
      "\n",
      "Learning rate: 2.7e-04\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: -0.5232 - val_loss: -0.4964\n",
      "\n",
      "Epoch 00051: val_loss did not improve from -0.52102\n",
      "\n",
      "Learning rate: 2.6e-04\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: -0.5317 - val_loss: -0.5219\n",
      "\n",
      "Epoch 00052: val_loss improved from -0.52102 to -0.52191, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: -0.5340 - val_loss: -0.4993\n",
      "\n",
      "Epoch 00053: val_loss did not improve from -0.52191\n",
      "\n",
      "Learning rate: 2.5e-04\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: -0.5366 - val_loss: -0.5257\n",
      "\n",
      "Epoch 00054: val_loss improved from -0.52191 to -0.52573, saving model to ../processed/model.h5\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: -0.5343 - val_loss: -0.5147\n",
      "\n",
      "Epoch 00055: val_loss did not improve from -0.52573\n",
      "\n",
      "Learning rate: 2.4e-04\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: -0.5388 - val_loss: -0.5094\n",
      "\n",
      "Epoch 00056: val_loss did not improve from -0.52573\n",
      "\n",
      "Learning rate: 2.3e-04\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: -0.5523 - val_loss: -0.5113\n",
      "\n",
      "Epoch 00057: val_loss did not improve from -0.52573\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 7221s 7s/step - loss: -0.5516 - val_loss: -0.5156\n",
      "\n",
      "Epoch 00058: val_loss did not improve from -0.52573\n",
      "\n",
      "Learning rate: 2.2e-04\n",
      "Epoch 59/100\n",
      " 185/1000 [====>.........................] - ETA: 11s - loss: -0.5660"
     ]
    }
   ],
   "source": [
    "train_oof((votes, answers), votes_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
