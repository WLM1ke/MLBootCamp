{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from sklearn import model_selection\n",
    "import pathlib\n",
    "\n",
    "COORDINATES = [\"Xmin\", \"Ymin\", \"Xmax\", \"Ymax\"]\n",
    "MAX_TRAIN_FORECASTS = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = pd.read_csv(\"../raw/train_data.csv\").set_index(\"itemId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = pd.read_csv(\"../raw/train_answers.csv\").set_index(\"itemId\")\n",
    "answers.columns = COORDINATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_test = pd.read_csv(\"../raw/test_data.csv\").set_index(\"itemId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_batch(batch_size):\n",
    "    while True:\n",
    "        item_id = np.random.choice(votes.index, 1)\n",
    "        forecasts = votes.loc[item_id].set_index(\"userId\")\n",
    "        x = np.zeros((1, len(forecasts), 4),)\n",
    "        y = np.zeros((1, 4))\n",
    "        \n",
    "        x[0] = forecasts.sample(len(forecasts))\n",
    "        y[0] = answers.loc[item_id]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_batch_val():\n",
    "    for item_id in :\n",
    "        item_id = np.random.choice(votes.index, 1)\n",
    "        forecasts = votes.loc[item_id].set_index(\"userId\")\n",
    "        x = np.zeros((1, len(forecasts), 4),)\n",
    "        y = np.zeros((1, 4))\n",
    "        \n",
    "        x[0] = forecasts.sample(len(forecasts))\n",
    "        y[0] = answers.loc[item_id]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(boxes_pred, boxes_true):\n",
    "\n",
    "    x_min = K.stack([boxes_pred[:, 0], boxes_true[:, 0]], axis=-1)\n",
    "    y_min = K.stack([boxes_pred[:, 1], boxes_true[:, 1]], axis=-1)\n",
    "    x_max = K.stack([boxes_pred[:, 2], boxes_true[:, 2]], axis=-1)\n",
    "    y_max = K.stack([boxes_pred[:, 3], boxes_true[:, 3]], axis=-1)\n",
    "\n",
    "    x_min = K.max(x_min, axis=-1)\n",
    "    y_min = K.max(y_min, axis=-1)\n",
    "    x_max = K.min(x_max, axis=-1)\n",
    "    y_max = K.min(y_max, axis=-1)\n",
    "\n",
    "    zeros = K.zeros_like(x_max)\n",
    "\n",
    "    x_inter = K.stack([zeros, x_max - x_min], axis=-1)\n",
    "    y_inter = K.stack([zeros, y_max - y_min], axis=-1)\n",
    "\n",
    "    x_inter = K.max(x_inter, axis=-1)\n",
    "    y_inter = K.max(y_inter, axis=-1)\n",
    "    inter_area = x_inter * y_inter\n",
    "    \n",
    "    area_pred = (K.max(K.stack([zeros, boxes_pred[:, 2] - boxes_pred[:, 0]], axis=-1), axis=-1) * \n",
    "                 K.max(K.stack([zeros, boxes_pred[:, 3] - boxes_pred[:, 1]], axis=-1), axis=-1))\n",
    "    area_true = (K.max(K.stack([zeros, boxes_true[:, 2] - boxes_true[:, 0]], axis=-1), axis=-1) * \n",
    "                 K.max(K.stack([zeros, boxes_true[:, 3] - boxes_true[:, 1]], axis=-1), axis=-1))\n",
    "\n",
    "    iou = inter_area / (area_pred + area_true - inter_area + K.epsilon())\n",
    "    \n",
    "    return -K.mean(iou, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(filters):\n",
    "    K.clear_session()\n",
    "    \n",
    "    y = x = layers.Input(shape=(None, 4))\n",
    "    y_rez = layers.GlobalAveragePooling1D()(y)\n",
    "    \n",
    "    y = layers.Bidirectional(layers.LSTM(\n",
    "        units=filters * 4,\n",
    "        return_sequences=False\n",
    "    ))(y)\n",
    "    # y = layers.GlobalAveragePooling1D()(y)\n",
    "    \n",
    "    y = layers.Dense(\n",
    "        units=filters * 4,\n",
    "        activation=\"relu\"\n",
    "    )(y)\n",
    "    y = layers.Dense(\n",
    "        units=filters * 2,\n",
    "        activation=\"relu\"\n",
    "    )(y)\n",
    "    y = layers.Dense(\n",
    "        units=filters,\n",
    "        activation=\"relu\"\n",
    "    )(y)\n",
    "    y = layers.Dense(\n",
    "        units=filters // 2,\n",
    "        activation=\"relu\"\n",
    "    )(y)\n",
    "    y = layers.Dense(\n",
    "        units=4,\n",
    "        activation=None\n",
    "    )(y)\n",
    "    y = layers.add([y_rez, y])\n",
    "    y = layers.Activation(\"relu\")(y)\n",
    "    \n",
    "    model = models.Model(inputs=x, outputs=y)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(batch_size, units, epochs=100):\n",
    "    model = make_model(units)\n",
    "    \n",
    "    lr=0.002\n",
    "    \n",
    "    model.compile(optimizer=optimizers.Nadam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004),\n",
    "                  loss=intersection_over_union,\n",
    "                  metrics=None\n",
    "    )\n",
    "    cb = [\n",
    "        callbacks.ModelCheckpoint(\"../processed/model.h5\", monitor=\"loss\", verbose=1, save_best_only=True),\n",
    "        callbacks.EarlyStopping(monitor='loss', patience=epochs // 10, verbose=10),\n",
    "        callbacks.ReduceLROnPlateau(monitor='loss', factor=0.8, patience=1, verbose=1)\n",
    "    ]\n",
    "    rez = model.fit_generator(\n",
    "        yield_batch(batch_size),\n",
    "        steps_per_epoch=1000 // batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=cb,\n",
    "        # validation_data=[make_feat(votes), answers],\n",
    "    )\n",
    "    return rez, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0718 16:38:45.471683 4619146688 deprecation_wrapper.py:119] From /Users/WLMike/Documents/PycharmProjects/ML_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W0718 16:38:45.472898 4619146688 deprecation_wrapper.py:119] From /Users/WLMike/Documents/PycharmProjects/ML_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0718 16:38:45.718407 4619146688 deprecation_wrapper.py:119] From /Users/WLMike/Documents/PycharmProjects/ML_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0718 16:38:45.719669 4619146688 deprecation_wrapper.py:119] From /Users/WLMike/Documents/PycharmProjects/ML_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0718 16:38:45.757680 4619146688 deprecation_wrapper.py:119] From /Users/WLMike/Documents/PycharmProjects/ML_venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0718 16:38:46.661823 4619146688 deprecation_wrapper.py:119] From /Users/WLMike/Documents/PycharmProjects/ML_venv/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 256)          136192      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           528         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 4)            0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4)            68          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 4)            0           global_average_pooling1d_1[0][0] \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 4)            0           add_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 180,020\n",
      "Trainable params: 180,020\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0718 16:38:47.472367 4619146688 deprecation.py:323] From /Users/WLMike/Documents/PycharmProjects/ML_venv/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: -0.5050\n",
      "\n",
      "Epoch 00001: loss improved from inf to -0.50501, saving model to ../processed/model.h5\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: -0.5031\n",
      "\n",
      "Epoch 00002: loss did not improve from -0.50501\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.001600000075995922.\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: -0.5080\n",
      "\n",
      "Epoch 00003: loss improved from -0.50501 to -0.50803, saving model to ../processed/model.h5\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: -0.4996\n",
      "\n",
      "Epoch 00004: loss did not improve from -0.50803\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0012800000607967378.\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: -0.5020\n",
      "\n",
      "Epoch 00005: loss did not improve from -0.50803\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0010240000672638416.\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: -0.5057\n",
      "\n",
      "Epoch 00006: loss did not improve from -0.50803\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0008192000910639763.\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: -0.5046\n",
      "\n",
      "Epoch 00007: loss did not improve from -0.50803\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006553600542247295.\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: -0.5024\n",
      "\n",
      "Epoch 00008: loss did not improve from -0.50803\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005242880433797836.\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: -0.5116\n",
      "\n",
      "Epoch 00009: loss improved from -0.50803 to -0.51157, saving model to ../processed/model.h5\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: -0.5046\n",
      "\n",
      "Epoch 00010: loss did not improve from -0.51157\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0004194304347038269.\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: -0.5055\n",
      "\n",
      "Epoch 00011: loss did not improve from -0.51157\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0003355443477630615.\n",
      "Epoch 12/100\n",
      " 372/1000 [==========>...................] - ETA: 5s - loss: -0.5193"
     ]
    }
   ],
   "source": [
    "rez, model = train_model(1, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rez.history)[[\"loss\", \"val_loss\"]].plot(figsize=(16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_forecast(model):\n",
    "    subdir = time.strftime('%Y-%m-%d_%H-%M')\n",
    "    path = pathlib.Path(f\"../processed/{subdir}\")\n",
    "    path.mkdir(exist_ok=True)\n",
    "    feat = make_feat(votes_test)\n",
    "    df = model.predict(feat)\n",
    "    df = pd.DataFrame(df, index=feat.index)\n",
    "    df.to_csv(path / \"_sub_full.csv\", header=False)\n",
    "    # path.rename(path.parent / f\"{subdir}-{score:0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_forecast(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
